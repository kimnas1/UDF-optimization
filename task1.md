# Task 1 — Анализ исходного скрипта и подготовка тест-датасета

---

## 1. Анализ `Create objects.sql`

**Модель:** OpenAI o3  
**Промпт:**  
> «Вы — старший инженер по БД в FAANG.  
> Проанализируйте предоставленный скрипт функции получения списка заказов и все связанные объекты.  
> Перечислите архитектурные недочёты и потенциальные проблемы производительности.»

### Найденные узкие места

1. **`F_WORKS_LIST` — многооператорная TVF**  
   *Табличная переменная `@RESULT` лишена статистики → tempdb и сериализация плана; неверные оценки размера выборки.*

2. **Два скалярных вызова `F_WORKITEMS_COUNT_BY_ID_WORK` на каждую строку**  
   *RBAR-паттерн: 3000 строк × 2 вызова = 6000 сканов `WorkItem`. Приводит к всплескам CPU и I/O.*

3. **`F_EMPLOYEE_FULLNAME` (вложенная `F_EMPLOYEE_GET`)**  
   *Скалярные UDF полностью отключают параллелизм до SQL 2019.*

4. **`NOT IN (SELECT … WHERE IS_GROUP = 1)`**  
   *Возможна «NULL-ловушка»; оптимизатор строит Anti Semi Join с непредсказуемыми планами.*

5. **`ORDER BY Id_Work DESC` без подходящего индекса**  
   *Требуется дорогостоящий оператор Sort.*

6. **Отсутствие индексов**  
   *Нет `(Id_Work, Is_Complit)` на `WorkItem` и `(CREATE_Date DESC, Id_Employee)` на `Works` ⇒ лавина Look-up’ов и скан всей таблицы.*

7. **CASE-логика для `Is_Print`**  
   *Пять проверок в каждой строке → лишняя CPU-нагрузка (не критично, но оптимизируемо).*

<details>
<summary>Полный вывод модели</summary>

Файл-приложение **`llm_response_task1.txt`**
</details>

---

## 2. Генерация тестовых данных

**Модель:** OpenAI o3  
**Промпт (кратко):**  
> «Напиши T-SQL-скрипт, который создаст правдоподобные данные:  
>  • 50 000 заказов (Works) со средней комплектацией ≈ 3;  
>  • 200 сотрудников (Employee) и 300 анализов (Analiz);  
>  • Соблюдай все внешние и уникальные ключи.»

После нескольких итераций получен финальный **`GenerateTestData.sql`**.

